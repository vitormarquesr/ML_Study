{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c00284e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e458aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e0d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ee210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce46e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255, X_train_full[5000:]/255\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7962cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21270a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90f6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79009259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bc37559",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b5374f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a773225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.05929804,  0.06355093, -0.01135698, ...,  0.04511974,\n",
       "          0.03163667, -0.03430772],\n",
       "        [-0.01013827,  0.01567693, -0.05477124, ...,  0.00225955,\n",
       "          0.04834915,  0.00175726],\n",
       "        [-0.00139235,  0.01228368,  0.04015785, ...,  0.01810025,\n",
       "         -0.05799886,  0.04655981],\n",
       "        ...,\n",
       "        [ 0.00307699,  0.07198466, -0.01636182, ...,  0.06241331,\n",
       "         -0.02622407,  0.0150905 ],\n",
       "        [-0.00238223, -0.00488541,  0.06846699, ..., -0.05025303,\n",
       "          0.0511878 ,  0.0469598 ],\n",
       "        [ 0.06346892, -0.04248867, -0.06112754, ...,  0.03469019,\n",
       "          0.05616094,  0.02702876]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e9d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8edc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7190 - accuracy: 0.7625 - val_loss: 0.5301 - val_accuracy: 0.8144\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4916 - accuracy: 0.8297 - val_loss: 0.5265 - val_accuracy: 0.8056\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4452 - accuracy: 0.8426 - val_loss: 0.4159 - val_accuracy: 0.8580\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4172 - accuracy: 0.8543 - val_loss: 0.4212 - val_accuracy: 0.8532\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3956 - accuracy: 0.8610 - val_loss: 0.3775 - val_accuracy: 0.8704\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3810 - accuracy: 0.8659 - val_loss: 0.3777 - val_accuracy: 0.8660\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3675 - accuracy: 0.8693 - val_loss: 0.3863 - val_accuracy: 0.8664\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3547 - accuracy: 0.8749 - val_loss: 0.3651 - val_accuracy: 0.8714\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3456 - accuracy: 0.8767 - val_loss: 0.3537 - val_accuracy: 0.8716\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3358 - accuracy: 0.8809 - val_loss: 0.3677 - val_accuracy: 0.8696\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3269 - accuracy: 0.8833 - val_loss: 0.3413 - val_accuracy: 0.8764\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3194 - accuracy: 0.8860 - val_loss: 0.3474 - val_accuracy: 0.8772\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3118 - accuracy: 0.8877 - val_loss: 0.3275 - val_accuracy: 0.8810\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3046 - accuracy: 0.8904 - val_loss: 0.3221 - val_accuracy: 0.8808\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2993 - accuracy: 0.8927 - val_loss: 0.3248 - val_accuracy: 0.8822\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2925 - accuracy: 0.8946 - val_loss: 0.3214 - val_accuracy: 0.8824\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2874 - accuracy: 0.8967 - val_loss: 0.3116 - val_accuracy: 0.8858\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2807 - accuracy: 0.8991 - val_loss: 0.3152 - val_accuracy: 0.8878\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2765 - accuracy: 0.9006 - val_loss: 0.3089 - val_accuracy: 0.8900\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2725 - accuracy: 0.9010 - val_loss: 0.3166 - val_accuracy: 0.8838\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2670 - accuracy: 0.9035 - val_loss: 0.3113 - val_accuracy: 0.8862\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2629 - accuracy: 0.9050 - val_loss: 0.3036 - val_accuracy: 0.8908\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2573 - accuracy: 0.9077 - val_loss: 0.3024 - val_accuracy: 0.8902\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2536 - accuracy: 0.9084 - val_loss: 0.3086 - val_accuracy: 0.8924\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2494 - accuracy: 0.9099 - val_loss: 0.3003 - val_accuracy: 0.8918\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2447 - accuracy: 0.9122 - val_loss: 0.2951 - val_accuracy: 0.8938\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2401 - accuracy: 0.9142 - val_loss: 0.3227 - val_accuracy: 0.8822\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2373 - accuracy: 0.9147 - val_loss: 0.3083 - val_accuracy: 0.8908\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2326 - accuracy: 0.9170 - val_loss: 0.2973 - val_accuracy: 0.8944\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2288 - accuracy: 0.9173 - val_loss: 0.2914 - val_accuracy: 0.8970\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c52600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f187b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3234429657459259, 0.8881999850273132]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test/255, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e56348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17374ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc7f98a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df42a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02fed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fa667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cd8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a611e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f3917d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05c9053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "99096d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dfd0e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b906855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5986 - val_loss: 0.5357\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5253 - val_loss: 0.6155\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4731 - val_loss: 0.7631\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4571 - val_loss: 0.9845\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 1.2020\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4316 - val_loss: 1.5052\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4224 - val_loss: 1.6880\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 1.9566\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4073 - val_loss: 2.1364\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 2.3286\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 2.5942\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3954 - val_loss: 2.9531\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3919 - val_loss: 3.1058\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 3.3778\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 3.6325\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3827 - val_loss: 3.9241\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 4.2957\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3764 - val_loss: 4.5923\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 4.7546\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 4.8040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "063abc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3749\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "81899cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37494349479675293"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29b74bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9ee87298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002046313B040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3b5f406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8376633],\n",
       "       [2.6049235],\n",
       "       [4.8294578]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "45b21e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.533  , 2.333  , 5.00001])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16a1b7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "85a9e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4a20b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(70, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(70, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1, activation='relu')(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=keras.optimizers.SGD(learning_rate=0.0003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4febdb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5006 - val_loss: 0.4818\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4985 - val_loss: 0.4814\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4965 - val_loss: 0.4816\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4947 - val_loss: 0.4824\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.4833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2045f8c5370>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b06dd4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4791037440299988"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "23549a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.73420274],\n",
       "       [2.7520154 ],\n",
       "       [4.906751  ]], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d0249d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.533  , 2.333  , 5.00001])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9884362",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4c55eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           270         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30)           930         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 38)           0           ['input_4[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            39          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9269bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.005), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b04b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2796 - val_loss: 0.3921\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2829 - val_loss: 0.3873\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2824 - val_loss: 0.4070\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2774 - val_loss: 0.4211\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2780 - val_loss: 0.4112\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2902 - val_loss: 0.3838\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.3874\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2763 - val_loss: 0.4151\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2874 - val_loss: 0.3694\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2897 - val_loss: 0.3812\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2754 - val_loss: 0.4142\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2787 - val_loss: 0.4082\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2761 - val_loss: 0.3810\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 0.3887\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2769 - val_loss: 0.3755\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2824 - val_loss: 0.4036\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2963 - val_loss: 0.3987\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2908 - val_loss: 0.3916\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.3867\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2871 - val_loss: 0.3935\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2829 - val_loss: 0.3920\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.3952\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.3892\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2750 - val_loss: 0.4018\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3881\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2961 - val_loss: 0.3821\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2740 - val_loss: 0.4133\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.4102\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.3538\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.4281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209e81a4580>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25dfc324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4154062569141388"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26007dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.9429421],\n",
       "        [2.1443338],\n",
       "        [3.1356215]], dtype=float32),\n",
       " array([1.125, 2.365, 2.545]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3]), y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4315eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94114341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 30)           930         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b31de9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb2a7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4806c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4245\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4257\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4161 - val_loss: 0.4307\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4308\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.4256\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.4244\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4211\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.4217\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.4220\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.4285\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4295\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4208\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4216\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4140\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3969 - val_loss: 0.4299\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4177\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3939 - val_loss: 0.4228\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4233\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4164\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3925 - val_loss: 0.4198\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4590\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit({'wide_input':X_train_A, 'deep_input':X_train_B}, y_train, epochs=20,\n",
    "    validation_data=((X_valid_A, X_valid_B), y_valid)),\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db31c266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45904725790023804"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f019bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.9467719],\n",
       "        [2.6801224],\n",
       "        [3.2498624]], dtype=float32),\n",
       " array([1.125, 2.365, 2.545]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92e8ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "inp_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hid1 = keras.layers.Dense(30, activation='relu')(inp_B)\n",
    "hid2 = keras.layers.Dense(30, activation='relu')(hid1)\n",
    "concat = keras.layers.Concatenate()([inp_B, hid2])\n",
    "out_layer = keras.layers.Dense(1, name='output_layer')(concat)\n",
    "aux_out = keras.layers.Dense(1, name='aux_output')(hid2)\n",
    "\n",
    "model = keras.Model(inputs=[inp_A, inp_B], outputs=[out_layer, aux_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a38a4a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 30)           930         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 36)           0           ['deep_input[0][0]',             \n",
      "                                                                  'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 1)            37          ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " aux_output (Dense)             (None, 1)            31          ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,208\n",
      "Trainable params: 1,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a9fef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.5, 0.5], optimizer=keras.optimizers.SGD(learning_rate=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c30afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3679 - output_layer_loss: 0.3675 - aux_output_loss: 0.3682 - val_loss: 0.4823 - val_output_layer_loss: 0.4837 - val_aux_output_loss: 0.4810\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3692 - output_layer_loss: 0.3701 - aux_output_loss: 0.3682 - val_loss: 0.5571 - val_output_layer_loss: 0.5665 - val_aux_output_loss: 0.5478\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3741 - output_layer_loss: 0.3799 - aux_output_loss: 0.3683 - val_loss: 0.5858 - val_output_layer_loss: 0.5844 - val_aux_output_loss: 0.5872\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3666 - output_layer_loss: 0.3670 - aux_output_loss: 0.3662 - val_loss: 0.4969 - val_output_layer_loss: 0.5060 - val_aux_output_loss: 0.4877\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3777 - output_layer_loss: 0.3888 - aux_output_loss: 0.3667 - val_loss: 0.4721 - val_output_layer_loss: 0.4723 - val_aux_output_loss: 0.4718\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - output_layer_loss: 0.3903 - aux_output_loss: 0.3649 - val_loss: 0.4725 - val_output_layer_loss: 0.4887 - val_aux_output_loss: 0.4562\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - output_layer_loss: 0.3844 - aux_output_loss: 0.3629 - val_loss: 0.5227 - val_output_layer_loss: 0.5226 - val_aux_output_loss: 0.5228\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3703 - output_layer_loss: 0.3793 - aux_output_loss: 0.3614 - val_loss: 0.4660 - val_output_layer_loss: 0.4775 - val_aux_output_loss: 0.4546\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3620 - output_layer_loss: 0.3637 - aux_output_loss: 0.3604 - val_loss: 0.4930 - val_output_layer_loss: 0.4861 - val_aux_output_loss: 0.5000\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3682 - output_layer_loss: 0.3752 - aux_output_loss: 0.3611 - val_loss: 0.4918 - val_output_layer_loss: 0.5007 - val_aux_output_loss: 0.4829\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3606 - output_layer_loss: 0.3633 - aux_output_loss: 0.3578 - val_loss: 0.5311 - val_output_layer_loss: 0.5267 - val_aux_output_loss: 0.5355\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3583 - output_layer_loss: 0.3585 - aux_output_loss: 0.3580 - val_loss: 0.5267 - val_output_layer_loss: 0.5301 - val_aux_output_loss: 0.5233\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - output_layer_loss: 0.3607 - aux_output_loss: 0.3580 - val_loss: 0.5383 - val_output_layer_loss: 0.5345 - val_aux_output_loss: 0.5420\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3574 - output_layer_loss: 0.3586 - aux_output_loss: 0.3563 - val_loss: 0.4455 - val_output_layer_loss: 0.4484 - val_aux_output_loss: 0.4426\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - output_layer_loss: 0.3590 - aux_output_loss: 0.3572 - val_loss: 0.4871 - val_output_layer_loss: 0.4798 - val_aux_output_loss: 0.4944\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - output_layer_loss: 0.3566 - aux_output_loss: 0.3575 - val_loss: 0.5051 - val_output_layer_loss: 0.5064 - val_aux_output_loss: 0.5038\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3568 - output_layer_loss: 0.3572 - aux_output_loss: 0.3564 - val_loss: 0.5363 - val_output_layer_loss: 0.5311 - val_aux_output_loss: 0.5416\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3562 - output_layer_loss: 0.3569 - aux_output_loss: 0.3554 - val_loss: 0.4712 - val_output_layer_loss: 0.4720 - val_aux_output_loss: 0.4703\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - output_layer_loss: 0.3537 - aux_output_loss: 0.3549 - val_loss: 0.4822 - val_output_layer_loss: 0.4806 - val_aux_output_loss: 0.4837\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - output_layer_loss: 0.3520 - aux_output_loss: 0.3534 - val_loss: 0.4103 - val_output_layer_loss: 0.4092 - val_aux_output_loss: 0.4115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B],\n",
    "    {'output_layer':y_train, 'aux_output':y_train}, epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c204798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5506 - output_layer_loss: 0.5505 - aux_output_loss: 0.5507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5505867004394531, 0.5505150556564331, 0.5506584048271179]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A, X_test_B), (y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7493d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([[1.402185 ],\n",
       "         [2.3814414],\n",
       "         [3.593187 ]], dtype=float32),\n",
       "  array([[1.4311949],\n",
       "         [2.3674545],\n",
       "         [3.6227407]], dtype=float32)],\n",
       " array([1.125, 2.365, 2.545]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict((X_test_A[:3], X_test_B[:3])), y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f01f1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f6ac6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "be54a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([[1.402185 ],\n",
       "         [2.3814414],\n",
       "         [3.593187 ]], dtype=float32),\n",
       "  array([[1.4311949],\n",
       "         [2.3674545],\n",
       "         [3.6227407]], dtype=float32)],\n",
       " array([1.125, 2.365, 2.545]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict((X_test_A[:3], X_test_B[:3])), y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03b06724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3426 - output_layer_loss: 0.3420 - aux_output_loss: 0.3432 - val_loss: 0.4393 - val_output_layer_loss: 0.4368 - val_aux_output_loss: 0.4419\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - output_layer_loss: 0.3418 - aux_output_loss: 0.3428 - val_loss: 0.4878 - val_output_layer_loss: 0.4902 - val_aux_output_loss: 0.4854\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3410 - output_layer_loss: 0.3406 - aux_output_loss: 0.3415 - val_loss: 0.4586 - val_output_layer_loss: 0.4559 - val_aux_output_loss: 0.4613\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - output_layer_loss: 0.3392 - aux_output_loss: 0.3398 - val_loss: 0.4151 - val_output_layer_loss: 0.4154 - val_aux_output_loss: 0.4148\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3407 - output_layer_loss: 0.3400 - aux_output_loss: 0.3413 - val_loss: 0.4349 - val_output_layer_loss: 0.4344 - val_aux_output_loss: 0.4355\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3403 - output_layer_loss: 0.3399 - aux_output_loss: 0.3406 - val_loss: 0.4786 - val_output_layer_loss: 0.4768 - val_aux_output_loss: 0.4805\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - output_layer_loss: 0.3396 - aux_output_loss: 0.3403 - val_loss: 0.4904 - val_output_layer_loss: 0.4883 - val_aux_output_loss: 0.4925\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - output_layer_loss: 0.3401 - aux_output_loss: 0.3396 - val_loss: 0.4794 - val_output_layer_loss: 0.4814 - val_aux_output_loss: 0.4774\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3387 - output_layer_loss: 0.3382 - aux_output_loss: 0.3392 - val_loss: 0.4421 - val_output_layer_loss: 0.4385 - val_aux_output_loss: 0.4458\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - output_layer_loss: 0.3380 - aux_output_loss: 0.3385 - val_loss: 0.5588 - val_output_layer_loss: 0.5530 - val_aux_output_loss: 0.5646\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - output_layer_loss: 0.3375 - aux_output_loss: 0.3392 - val_loss: 0.4099 - val_output_layer_loss: 0.4100 - val_aux_output_loss: 0.4099\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3381 - output_layer_loss: 0.3374 - aux_output_loss: 0.3387 - val_loss: 0.4292 - val_output_layer_loss: 0.4284 - val_aux_output_loss: 0.4301\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3385 - output_layer_loss: 0.3386 - aux_output_loss: 0.3383 - val_loss: 0.4488 - val_output_layer_loss: 0.4539 - val_aux_output_loss: 0.4437\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3360 - output_layer_loss: 0.3354 - aux_output_loss: 0.3366 - val_loss: 0.5204 - val_output_layer_loss: 0.5145 - val_aux_output_loss: 0.5262\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3357 - output_layer_loss: 0.3352 - aux_output_loss: 0.3362 - val_loss: 0.4667 - val_output_layer_loss: 0.4650 - val_aux_output_loss: 0.4683\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3381 - output_layer_loss: 0.3378 - aux_output_loss: 0.3384 - val_loss: 0.4146 - val_output_layer_loss: 0.4159 - val_aux_output_loss: 0.4134\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - output_layer_loss: 0.3349 - aux_output_loss: 0.3353 - val_loss: 0.4578 - val_output_layer_loss: 0.4566 - val_aux_output_loss: 0.4590\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3345 - output_layer_loss: 0.3341 - aux_output_loss: 0.3349 - val_loss: 0.4182 - val_output_layer_loss: 0.4166 - val_aux_output_loss: 0.4198\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3364 - output_layer_loss: 0.3366 - aux_output_loss: 0.3363 - val_loss: 0.4306 - val_output_layer_loss: 0.4297 - val_aux_output_loss: 0.4316\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - output_layer_loss: 0.3360 - aux_output_loss: 0.3358 - val_loss: 0.5084 - val_output_layer_loss: 0.5068 - val_aux_output_loss: 0.5101\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3346 - output_layer_loss: 0.3344 - aux_output_loss: 0.3348 - val_loss: 0.3944 - val_output_layer_loss: 0.3944 - val_aux_output_loss: 0.3945\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3339 - output_layer_loss: 0.3335 - aux_output_loss: 0.3343 - val_loss: 0.4315 - val_output_layer_loss: 0.4325 - val_aux_output_loss: 0.4305\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3346 - output_layer_loss: 0.3344 - aux_output_loss: 0.3348 - val_loss: 0.4525 - val_output_layer_loss: 0.4512 - val_aux_output_loss: 0.4537\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3343 - output_layer_loss: 0.3343 - aux_output_loss: 0.3343 - val_loss: 0.4745 - val_output_layer_loss: 0.4736 - val_aux_output_loss: 0.4754\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3336 - output_layer_loss: 0.3340 - aux_output_loss: 0.3331 - val_loss: 0.4001 - val_output_layer_loss: 0.4015 - val_aux_output_loss: 0.3988\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3338 - output_layer_loss: 0.3341 - aux_output_loss: 0.3334 - val_loss: 0.4279 - val_output_layer_loss: 0.4323 - val_aux_output_loss: 0.4235\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3328 - output_layer_loss: 0.3343 - aux_output_loss: 0.3314 - val_loss: 0.4439 - val_output_layer_loss: 0.4423 - val_aux_output_loss: 0.4455\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3333 - output_layer_loss: 0.3346 - aux_output_loss: 0.3320 - val_loss: 0.4438 - val_output_layer_loss: 0.4447 - val_aux_output_loss: 0.4429\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3325 - output_layer_loss: 0.3329 - aux_output_loss: 0.3322 - val_loss: 0.4212 - val_output_layer_loss: 0.4199 - val_aux_output_loss: 0.4224\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - output_layer_loss: 0.3307 - aux_output_loss: 0.3305 - val_loss: 0.4076 - val_output_layer_loss: 0.4092 - val_aux_output_loss: 0.4061\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit((X_train_A, X_train_B), (y_train,y_train), epochs=30, \n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08e7949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96df9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5416 - output_layer_loss: 0.5423 - aux_output_loss: 0.5409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5416127443313599, 0.5423080921173096, 0.5409177541732788]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A, X_test_B), (y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d56affcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3274 - output_layer_loss: 0.3270 - aux_output_loss: 0.3278 - val_loss: 0.4436 - val_output_layer_loss: 0.4434 - val_aux_output_loss: 0.4438\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3278 - output_layer_loss: 0.3274 - aux_output_loss: 0.3282 - val_loss: 0.4447 - val_output_layer_loss: 0.4430 - val_aux_output_loss: 0.4464\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3267 - output_layer_loss: 0.3264 - aux_output_loss: 0.3269 - val_loss: 0.4489 - val_output_layer_loss: 0.4487 - val_aux_output_loss: 0.4491\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3269 - output_layer_loss: 0.3266 - aux_output_loss: 0.3273 - val_loss: 0.4416 - val_output_layer_loss: 0.4420 - val_aux_output_loss: 0.4412\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3266 - output_layer_loss: 0.3266 - aux_output_loss: 0.3267 - val_loss: 0.4322 - val_output_layer_loss: 0.4325 - val_aux_output_loss: 0.4319\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3268 - output_layer_loss: 0.3266 - aux_output_loss: 0.3269 - val_loss: 0.4210 - val_output_layer_loss: 0.4214 - val_aux_output_loss: 0.4207\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - output_layer_loss: 0.3260 - aux_output_loss: 0.3264 - val_loss: 0.4300 - val_output_layer_loss: 0.4304 - val_aux_output_loss: 0.4296\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3259 - output_layer_loss: 0.3256 - aux_output_loss: 0.3263 - val_loss: 0.4423 - val_output_layer_loss: 0.4415 - val_aux_output_loss: 0.4431\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3258 - output_layer_loss: 0.3255 - aux_output_loss: 0.3261 - val_loss: 0.4220 - val_output_layer_loss: 0.4224 - val_aux_output_loss: 0.4216\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3251 - output_layer_loss: 0.3249 - aux_output_loss: 0.3254 - val_loss: 0.4274 - val_output_layer_loss: 0.4285 - val_aux_output_loss: 0.4263\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3242 - output_layer_loss: 0.3239 - aux_output_loss: 0.3244 - val_loss: 0.4495 - val_output_layer_loss: 0.4491 - val_aux_output_loss: 0.4500\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3248 - output_layer_loss: 0.3245 - aux_output_loss: 0.3252 - val_loss: 0.4307 - val_output_layer_loss: 0.4305 - val_aux_output_loss: 0.4310\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3246 - output_layer_loss: 0.3243 - aux_output_loss: 0.3249 - val_loss: 0.4250 - val_output_layer_loss: 0.4262 - val_aux_output_loss: 0.4238\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3243 - output_layer_loss: 0.3239 - aux_output_loss: 0.3246 - val_loss: 0.4846 - val_output_layer_loss: 0.4848 - val_aux_output_loss: 0.4844\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3234 - output_layer_loss: 0.3230 - aux_output_loss: 0.3237 - val_loss: 0.4327 - val_output_layer_loss: 0.4325 - val_aux_output_loss: 0.4328\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3244 - output_layer_loss: 0.3241 - aux_output_loss: 0.3248 - val_loss: 0.4610 - val_output_layer_loss: 0.4595 - val_aux_output_loss: 0.4624\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3239 - output_layer_loss: 0.3235 - aux_output_loss: 0.3242 - val_loss: 0.4439 - val_output_layer_loss: 0.4436 - val_aux_output_loss: 0.4441\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3234 - output_layer_loss: 0.3232 - aux_output_loss: 0.3237 - val_loss: 0.3851 - val_output_layer_loss: 0.3855 - val_aux_output_loss: 0.3846\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3229 - output_layer_loss: 0.3227 - aux_output_loss: 0.3232 - val_loss: 0.4638 - val_output_layer_loss: 0.4645 - val_aux_output_loss: 0.4631\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - output_layer_loss: 0.3216 - aux_output_loss: 0.3221 - val_loss: 0.4304 - val_output_layer_loss: 0.4312 - val_aux_output_loss: 0.4297\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3233 - output_layer_loss: 0.3230 - aux_output_loss: 0.3236 - val_loss: 0.4222 - val_output_layer_loss: 0.4221 - val_aux_output_loss: 0.4223\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3224 - output_layer_loss: 0.3222 - aux_output_loss: 0.3226 - val_loss: 0.4665 - val_output_layer_loss: 0.4661 - val_aux_output_loss: 0.4670\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3230 - output_layer_loss: 0.3227 - aux_output_loss: 0.3232 - val_loss: 0.4191 - val_output_layer_loss: 0.4186 - val_aux_output_loss: 0.4196\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3224 - output_layer_loss: 0.3222 - aux_output_loss: 0.3227 - val_loss: 0.4235 - val_output_layer_loss: 0.4232 - val_aux_output_loss: 0.4237\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3217 - output_layer_loss: 0.3214 - aux_output_loss: 0.3219 - val_loss: 0.4403 - val_output_layer_loss: 0.4399 - val_aux_output_loss: 0.4406\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - output_layer_loss: 0.3216 - aux_output_loss: 0.3222 - val_loss: 0.4053 - val_output_layer_loss: 0.4059 - val_aux_output_loss: 0.4046\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - output_layer_loss: 0.3217 - aux_output_loss: 0.3220 - val_loss: 0.3941 - val_output_layer_loss: 0.3953 - val_aux_output_loss: 0.3928\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3219 - output_layer_loss: 0.3217 - aux_output_loss: 0.3221 - val_loss: 0.4644 - val_output_layer_loss: 0.4650 - val_aux_output_loss: 0.4637\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3215 - output_layer_loss: 0.3213 - aux_output_loss: 0.3217 - val_loss: 0.4344 - val_output_layer_loss: 0.4344 - val_aux_output_loss: 0.4343\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3221 - output_layer_loss: 0.3220 - aux_output_loss: 0.3222 - val_loss: 0.4042 - val_output_layer_loss: 0.4045 - val_aux_output_loss: 0.4040\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3207 - output_layer_loss: 0.3205 - aux_output_loss: 0.3208 - val_loss: 0.4144 - val_output_layer_loss: 0.4146 - val_aux_output_loss: 0.4143\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3205 - output_layer_loss: 0.3204 - aux_output_loss: 0.3206 - val_loss: 0.4103 - val_output_layer_loss: 0.4122 - val_aux_output_loss: 0.4085\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3212 - output_layer_loss: 0.3211 - aux_output_loss: 0.3213 - val_loss: 0.3973 - val_output_layer_loss: 0.3981 - val_aux_output_loss: 0.3965\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3208 - output_layer_loss: 0.3206 - aux_output_loss: 0.3211 - val_loss: 0.4285 - val_output_layer_loss: 0.4291 - val_aux_output_loss: 0.4280\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3205 - output_layer_loss: 0.3204 - aux_output_loss: 0.3207 - val_loss: 0.4458 - val_output_layer_loss: 0.4462 - val_aux_output_loss: 0.4454\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3206 - output_layer_loss: 0.3204 - aux_output_loss: 0.3208 - val_loss: 0.4330 - val_output_layer_loss: 0.4322 - val_aux_output_loss: 0.4338\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3216 - output_layer_loss: 0.3212 - aux_output_loss: 0.3219 - val_loss: 0.4187 - val_output_layer_loss: 0.4193 - val_aux_output_loss: 0.4182\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3199 - output_layer_loss: 0.3197 - aux_output_loss: 0.3201 - val_loss: 0.4177 - val_output_layer_loss: 0.4185 - val_aux_output_loss: 0.4168\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "history = model.fit((X_train_A, X_train_B), (y_train,y_train), epochs=100, \n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)),\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1e06959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5289 - output_layer_loss: 0.5299 - aux_output_loss: 0.5279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5288987159729004, 0.5298771858215332, 0.5279200077056885]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A, X_test_B), (y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c060e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44aef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input(shape=X_train.shape[1:], name='Input')\n",
    "hidd1 = keras.layers.Dense(30, name='Hidden1')(inp)\n",
    "hidd2 = keras.layers.Dense(30, name='Hidden2')(hidd1)\n",
    "outp = keras.layers.Dense(1, name='OutputLayer')(hidd2)\n",
    "model = keras.Model(inputs=[inp], outputs=[outp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c14abc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02688aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75689aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, 'my_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d67af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a9af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3266d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5049 - val_loss: 0.6569\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6153 - val_loss: 0.8368\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0312 - val_loss: 0.5992\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5836 - val_loss: 0.4949\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5610 - val_loss: 0.5517\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.4905\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5605 - val_loss: 0.4760\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.5098\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5683 - val_loss: 0.4599\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5402 - val_loss: 0.5207\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5637 - val_loss: 0.4898\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5432 - val_loss: 0.5277\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5524 - val_loss: 0.4782\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5420 - val_loss: 0.4736\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5391 - val_loss: 0.4826\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5538 - val_loss: 0.5065\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5492 - val_loss: 0.4802\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5428 - val_loss: 0.4645\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5492 - val_loss: 0.4874\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.4787\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.4801\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5563 - val_loss: 0.4763\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5489 - val_loss: 0.4766\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5375 - val_loss: 0.4570\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5700 - val_loss: 0.4933\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5378 - val_loss: 0.4915\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5392 - val_loss: 0.4654\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5502 - val_loss: 0.4580\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5629 - val_loss: 0.4856\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5391 - val_loss: 0.4875\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88348266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a847b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmrod\\AppData\\Local\\Temp/ipykernel_12592/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc9af990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4549 - val_loss: 0.6962\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6743 - val_loss: 0.5638\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6082 - val_loss: 0.5050\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5564 - val_loss: 0.4518\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 0.4430\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5082 - val_loss: 0.4221\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4923 - val_loss: 0.4242\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4894 - val_loss: 0.4258\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4794 - val_loss: 0.4222\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4752 - val_loss: 0.4396\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4685 - val_loss: 0.4428\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4668 - val_loss: 0.4643\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4623 - val_loss: 0.4654\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4614 - val_loss: 0.4873\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4576 - val_loss: 0.5068\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4541 - val_loss: 0.5145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f83c90c220>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=keras.callbacks.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09444e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a28aa1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4469\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea776947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.44685816764831543, array([1.2117267, 1.4810058, 1.6739554], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f879fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56b2d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98009cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.6631 - val_loss: 3.8181\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.5035 - val_loss: 2.8682\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6785 - val_loss: 2.1944\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0903 - val_loss: 1.7166\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6704 - val_loss: 1.3767\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3702 - val_loss: 1.1354\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1551 - val_loss: 0.9632\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 0.8406\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 0.7531\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8092 - val_loss: 0.6907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7511 - val_loss: 0.6461\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7090 - val_loss: 0.6140\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6782 - val_loss: 0.5909\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6556 - val_loss: 0.5746\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6389 - val_loss: 0.5623\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6264 - val_loss: 0.5534\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.5467\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.5416\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.5376\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.5346\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5959 - val_loss: 0.5320\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.5299\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5904 - val_loss: 0.5281\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5882 - val_loss: 0.5264\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 0.5251\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5846 - val_loss: 0.5237\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5830 - val_loss: 0.5226\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5815 - val_loss: 0.5213\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 0.5202\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5789 - val_loss: 0.5191\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 0.5180\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.5169\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 0.5159\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5742 - val_loss: 0.5150\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5732 - val_loss: 0.5139\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5722 - val_loss: 0.5129\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - val_loss: 0.5120\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 0.5110\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - val_loss: 0.5101\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 0.5091\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5674 - val_loss: 0.5083\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5665 - val_loss: 0.5075\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 0.5066\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.5057\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5640 - val_loss: 0.5048\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5632 - val_loss: 0.5040\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 0.5032\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.5025\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.5018\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5011\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5595 - val_loss: 0.5003\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 0.4997\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 0.4990\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.4984\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - val_loss: 0.4977\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5561 - val_loss: 0.4971\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.4966\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 0.4959\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 0.4953\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 0.4947\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5531 - val_loss: 0.4942\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5526 - val_loss: 0.4937\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.4931\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 0.4927\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5510 - val_loss: 0.4922\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5505 - val_loss: 0.4918\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5500 - val_loss: 0.4914\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 0.4910\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.4905\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 0.4900\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5481 - val_loss: 0.4896\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.4892\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.4889\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.4885\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.4880\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4877\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5455 - val_loss: 0.4873\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 0.4870\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 0.4867\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.4864\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.4862\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5437 - val_loss: 0.4859\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5434 - val_loss: 0.4855\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5430 - val_loss: 0.4851\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.4849\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 0.4847\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 0.4844\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.4842\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.4840\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.4838\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.4835\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.4834\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.4831\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.4829\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.4826\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.4825\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5392 - val_loss: 0.4822\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 0.4821\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.4818\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 0.4816\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5516\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.0009 - val_loss: 5.8659\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.4445 - val_loss: 4.4737\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.3578 - val_loss: 3.4821\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.5920 - val_loss: 2.7682\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0485 - val_loss: 2.2516\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6610 - val_loss: 1.8719\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3830 - val_loss: 1.5917\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1825 - val_loss: 1.3821\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0372 - val_loss: 1.2237\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 1.1024\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8530 - val_loss: 1.0088\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.9348\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.8759\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7193 - val_loss: 0.8284\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6945 - val_loss: 0.7892\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 0.7565\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6603 - val_loss: 0.7289\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6482 - val_loss: 0.7053\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6386 - val_loss: 0.6847\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.6669\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6512\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6186 - val_loss: 0.6371\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6246\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6134\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6032\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.5939\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.5856\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 0.5779\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 0.5708\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.5643\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 0.5582\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5893 - val_loss: 0.5527\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.5476\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5860 - val_loss: 0.5430\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5846 - val_loss: 0.5385\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5832 - val_loss: 0.5345\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5819 - val_loss: 0.5306\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5807 - val_loss: 0.5271\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 0.5238\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - val_loss: 0.5208\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - val_loss: 0.5179\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5767 - val_loss: 0.5153\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5758 - val_loss: 0.5128\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5748 - val_loss: 0.5106\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 0.5084\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - val_loss: 0.5061\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - val_loss: 0.5042\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5719 - val_loss: 0.5023\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5712 - val_loss: 0.5005\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5705 - val_loss: 0.4988\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5699 - val_loss: 0.4972\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5694 - val_loss: 0.4958\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.4945\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.4931\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5677 - val_loss: 0.4919\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 0.4908\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - val_loss: 0.4898\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - val_loss: 0.4886\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 0.4877\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.4869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.4860\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5644 - val_loss: 0.4852\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - val_loss: 0.4844\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - val_loss: 0.4836\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.4827\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5627 - val_loss: 0.4821\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 0.4814\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 0.4807\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.4800\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.4794\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5610 - val_loss: 0.4789\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5607 - val_loss: 0.4784\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5604 - val_loss: 0.4780\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 0.4774\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5598 - val_loss: 0.4769\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5595 - val_loss: 0.4764\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5592 - val_loss: 0.4758\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5589 - val_loss: 0.4754\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5587 - val_loss: 0.4749\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5583 - val_loss: 0.4745\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 0.4741\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 0.4739\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 0.4736\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5574 - val_loss: 0.4732\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5571 - val_loss: 0.4728\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5569 - val_loss: 0.4724\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5566 - val_loss: 0.4722\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5564 - val_loss: 0.4719\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 0.4716\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5559 - val_loss: 0.4712\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 0.4711\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.4707\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 0.4706\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 0.4704\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5550 - val_loss: 0.4701\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.4699\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 0.4696\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 0.4695\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5542 - val_loss: 0.4691\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.4689\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5175\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.8087 - val_loss: 6.2085\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.3736 - val_loss: 4.3708\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8112 - val_loss: 3.1679\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7886 - val_loss: 2.3651\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1068 - val_loss: 1.8207\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6449 - val_loss: 1.4456\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3282 - val_loss: 1.1842\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1087 - val_loss: 1.0008\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.8710\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8478 - val_loss: 0.7785\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7716 - val_loss: 0.7121\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.6643\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 0.6295\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 0.6042\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.5857\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5717\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.5612\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.5531\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5904 - val_loss: 0.5468\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5856 - val_loss: 0.5419\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5819 - val_loss: 0.5379\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5788 - val_loss: 0.5346\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5763 - val_loss: 0.5318\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.5294\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.5272\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.5253\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5694 - val_loss: 0.5236\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - val_loss: 0.5220\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5669 - val_loss: 0.5205\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5658 - val_loss: 0.5192\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 0.5178\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - val_loss: 0.5166\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - val_loss: 0.5154\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.5141\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - val_loss: 0.5130\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 0.5120\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.5109\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 0.5099\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 0.5089\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 0.5080\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 0.5070\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5550 - val_loss: 0.5061\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5542 - val_loss: 0.5052\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.5043\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 0.5035\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5521 - val_loss: 0.5027\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.5018\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5508 - val_loss: 0.5011\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5501 - val_loss: 0.5004\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 0.4997\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 0.4989\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.4981\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.4975\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.4968\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.4961\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 0.4955\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5455 - val_loss: 0.4949\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.4943\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 0.4937\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5440 - val_loss: 0.4932\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 0.4926\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.4921\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 0.4916\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 0.4910\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.4905\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.4900\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.4896\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.4891\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 0.4887\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.4884\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 0.4879\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.4875\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 0.4871\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.4868\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.4864\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.4859\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.4856\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.4854\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.4850\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5363 - val_loss: 0.4847\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.4844\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.4840\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.4836\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.4832\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5348 - val_loss: 0.4829\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 0.4826\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5343 - val_loss: 0.4823\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.4820\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.4817\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 0.4814\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.4811\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5331 - val_loss: 0.4809\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5329 - val_loss: 0.4806\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.4804\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 0.4802\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.4800\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 0.4799\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.4796\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 0.4793\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.4790\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5772\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8166 - val_loss: 0.5138\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 0.4792\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5166\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.6291\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.7157\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.9750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 1.0429\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 1.3682\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 1.4162\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 1.8066\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 1.9714\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 2.2985\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9158 - val_loss: 0.5065\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.4949\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5688\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.7270\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.9481\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 1.1027\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 1.4007\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 1.4175\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 1.9926\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 2.2071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 2.7123\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3782\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9870 - val_loss: 0.9030\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.7547\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 1.1626\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 1.4416\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 1.7858\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 2.0595\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 2.4490\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 2.7925\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 3.1525\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 3.3403\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 3.5902\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 3.8679\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4057\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5929 - val_loss: 0.6213\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.5166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.4775\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 0.4608\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.4644\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.4620\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4869\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.5131\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.5421\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 0.5520\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.5783\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.6128\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.6752\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.6895\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4155\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5045 - val_loss: 0.6738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6657 - val_loss: 0.5649\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 0.5076\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.4694\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5245 - val_loss: 0.4399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5004 - val_loss: 0.4271\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4857 - val_loss: 0.4198\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.4214\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.4029\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.4136\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4142\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.4382\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4529\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4514\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4871\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 0.4931\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.5160\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.5383\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.5831\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4029\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4856 - val_loss: 0.6775\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6550 - val_loss: 0.5908\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 0.5509\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 0.5299\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.5100\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5074 - val_loss: 0.4923\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.4839\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.4659\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 0.4604\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4418\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4286\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.4264\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4170\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4230\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4118\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4294\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.4171\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4417\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4337\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4773\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4387\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4996\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4862\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.5489\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.5581\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4390\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9460 - val_loss: 3.1619\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8085 - val_loss: 0.8242\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 1.3136\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8226 - val_loss: 0.5198\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 0.5771\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.4438\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.4618\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.7219\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.7959\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.8960\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 1.1129\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 1.4309\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 1.5252\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 1.6664\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 1.8798\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 2.1248\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3685\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9030 - val_loss: 11.4057\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2405 - val_loss: 0.9922\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8851 - val_loss: 0.7130\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7366 - val_loss: 0.6722\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6981 - val_loss: 0.6377\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6687 - val_loss: 0.6108\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6437 - val_loss: 0.5859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.5638\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6032 - val_loss: 0.5444\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.5289\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 0.5146\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 0.4984\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5517 - val_loss: 0.4870\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.4782\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.4697\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.4603\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5229 - val_loss: 0.4528\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.4455\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5128 - val_loss: 0.4386\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.4352\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5041 - val_loss: 0.4295\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5004 - val_loss: 0.4283\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.4210\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.4194\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.4158\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.4110\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.4109\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.4084\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4802 - val_loss: 0.4071\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4778 - val_loss: 0.4067\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.4032\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 0.4014\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4712 - val_loss: 0.3986\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.3994\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.4017\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4654 - val_loss: 0.4007\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4638 - val_loss: 0.4023\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4043\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4039\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.4091\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.4074\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.4140\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4109\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4587\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2045 - val_loss: 0.8045\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8450 - val_loss: 0.6837\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7598 - val_loss: 0.6378\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7156 - val_loss: 0.6001\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6827 - val_loss: 0.5731\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6560 - val_loss: 0.5497\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6337 - val_loss: 0.5321\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6142 - val_loss: 0.5164\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5987 - val_loss: 0.5043\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5854 - val_loss: 0.4914\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5728 - val_loss: 0.4836\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5631 - val_loss: 0.4748\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.4686\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.4628\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.4580\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.4570\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.4473\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.4469\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.4450\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 0.4420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.4408\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.4410\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.4423\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.4406\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.4410\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.4391\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.4411\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4436\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.4460\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4484\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.4480\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.4527\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.4512\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4545\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.4572\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.4590\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4484\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1059 - val_loss: 0.8613\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8236 - val_loss: 0.6591\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7026 - val_loss: 0.6081\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6658 - val_loss: 0.5776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.5540\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5318\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 0.5128\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5787 - val_loss: 0.4954\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.4808\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.4686\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5388 - val_loss: 0.4578\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.4466\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.4381\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.4321\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.4281\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.4231\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.4168\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.4148\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.4151\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.4113\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.4073\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.4065\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.4030\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.4057\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.4052\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.4056\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.4066\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.4029\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.4035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.4069\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.4080\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.4069\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.4093\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4092\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4131\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.4143\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4145\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4490 - val_loss: 0.4192\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4830\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7641 - val_loss: 33.8011\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8490 - val_loss: 0.9690\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8083 - val_loss: 0.8192\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.5753\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5629 - val_loss: 0.4933\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5279\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6327\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.7624\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.8401\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.9052\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 1.1930\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.9436\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 1.1071\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 1.3873\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 1.4480\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3928\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8460 - val_loss: 2.2419\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.7241 - val_loss: 4627.0522\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9732 - val_loss: 2196.1621\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1559 - val_loss: 1328.4738\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7148 - val_loss: 1067.0620\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5832 - val_loss: 1020.3685\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4960 - val_loss: 999.5753\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 986.5394\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 980.9684\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 971.4960\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 969.2377\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4933\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3641 - val_loss: 0.8977\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8378 - val_loss: 0.6716\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7038 - val_loss: 0.6276\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6695 - val_loss: 0.5969\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.5717\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.5468\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6036 - val_loss: 0.5311\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5869 - val_loss: 0.5098\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5728 - val_loss: 0.4966\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - val_loss: 0.4803\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5479 - val_loss: 0.4695\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.4571\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.4453\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 0.4414\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5120 - val_loss: 0.4312\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.4288\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.4195\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.4152\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.4091\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.4061\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4053\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4018\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4710 - val_loss: 0.3961\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4677 - val_loss: 0.3978\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.3949\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.3919\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4587 - val_loss: 0.3914\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4560 - val_loss: 0.3980\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.3931\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4031\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.3970\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.3976\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.3988\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.3989\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4053\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4049\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4161\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4472\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7467 - val_loss: 0.7460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8350 - val_loss: 0.6488\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7527 - val_loss: 0.6095\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7114 - val_loss: 0.5806\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6803 - val_loss: 0.5551\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6541 - val_loss: 0.5376\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.5166\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.5017\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5933 - val_loss: 0.4953\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 0.4812\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - val_loss: 0.4759\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.4705\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.4654\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.4659\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.4646\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.4668\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.4650\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.4667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.4683\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.4750\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4840 - val_loss: 0.4812\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4798 - val_loss: 0.4954\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4760 - val_loss: 0.5026\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4725 - val_loss: 0.5054\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5133\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4398\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6024 - val_loss: 1.0271\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9099 - val_loss: 0.6568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7009 - val_loss: 0.5841\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.5545\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.5325\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5936 - val_loss: 0.5132\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 0.4958\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5597 - val_loss: 0.4806\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.4673\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 0.4552\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4451\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.4352\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.4262\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.4184\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.4111\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.4055\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.4007\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.3983\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.3939\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.3916\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.3893\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.3885\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.3866\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.3880\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.3867\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.3864\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.3883\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.3872\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.3894\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.3900\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4386 - val_loss: 0.3922\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4372 - val_loss: 0.3962\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.3991\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4020\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4034\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4067\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4666\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0807 - val_loss: 0.5460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 0.4416\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.4044\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.3749\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4426 - val_loss: 0.4089\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4316 - val_loss: 0.4114\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.5004\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.5293\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.5988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.7368\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.7026\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.8160\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 1.0176\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 1.0463\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3815\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9677 - val_loss: 0.5271\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5694 - val_loss: 0.4319\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5101 - val_loss: 0.4152\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4629\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4572 - val_loss: 0.4689\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4447 - val_loss: 0.5182\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.5683\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.7288\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4161 - val_loss: 0.7165\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.7626\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.9681\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.9437\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 1.1256\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3726\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1103 - val_loss: 1.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7871 - val_loss: 0.5758\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8182 - val_loss: 0.4774\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.4464\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4455 - val_loss: 0.4896\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.5542\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.6200\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.6970\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.8089\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.9980\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.9870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 1.2493\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 1.4086\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 1.5218\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3988\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6934 - val_loss: 0.5445\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.6864\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 1.0162\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 1.2549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 2.0877\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 2.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 2.6322\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 3.0054\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 3.6997\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 4.7403\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 4.2191\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4200\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8128 - val_loss: 0.9807\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.4095\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.4537\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.5683\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.8485\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 1.0594\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 1.0040\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 1.4104\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 1.8001\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 2.1343\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 2.6624\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 2.8499\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3396\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0705 - val_loss: 1.1770\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0450 - val_loss: 0.8873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 3.1770\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 4.6287\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 4.8123\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 5.0326\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 4.6834\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 4.1703\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 4.3579\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 3.3343\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 3.0693\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 2.2380\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3842\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.4033 - val_loss: 2.7112\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0172 - val_loss: 1.5030\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1925 - val_loss: 1.0793\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8870 - val_loss: 0.9186\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7670 - val_loss: 0.8502\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7155 - val_loss: 0.8143\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.7901\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6744 - val_loss: 0.7687\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6630 - val_loss: 0.7514\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6536 - val_loss: 0.7332\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6454 - val_loss: 0.7175\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6380 - val_loss: 0.7023\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.6878\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.6742\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.6616\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6486\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6374\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6275\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6169\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5941 - val_loss: 0.6084\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 0.6000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 0.5917\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5827 - val_loss: 0.5831\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.5748\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5763 - val_loss: 0.5692\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - val_loss: 0.5631\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 0.5572\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - val_loss: 0.5517\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 0.5471\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5634 - val_loss: 0.5419\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.5372\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 0.5326\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.5286\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 0.5251\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.5221\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.5193\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5510 - val_loss: 0.5156\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5497 - val_loss: 0.5132\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.5103\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.5076\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.5052\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.5034\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.5011\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5431 - val_loss: 0.5001\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 0.4977\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.4962\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.4944\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5399 - val_loss: 0.4929\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 0.4913\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 0.4901\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 0.4893\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.4875\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.4873\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5364 - val_loss: 0.4861\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.4853\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 0.4841\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.4832\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.4825\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5343 - val_loss: 0.4811\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.4818\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.4817\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.4807\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5330 - val_loss: 0.4794\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5327 - val_loss: 0.4784\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 0.4795\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.4787\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.4783\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.4778\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.4777\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.4779\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.4768\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.4763\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.4764\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.4761\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.4753\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.4747\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.4759\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.4758\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.4755\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 0.4752\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.4750\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.4756\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.4755\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.4751\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.4749\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5295 - val_loss: 0.4745\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.4744\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.4745\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 0.4743\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.4753\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.4748\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.4750\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.4737\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.4737\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.4742\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.4750\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.4750\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.4748\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.4744\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.4747\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5482\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.4656 - val_loss: 2.6062\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0035 - val_loss: 1.3127\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1525 - val_loss: 0.8643\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8417 - val_loss: 0.7031\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 0.6416\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6738 - val_loss: 0.6150\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6508 - val_loss: 0.6006\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6380 - val_loss: 0.5897\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.5806\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.5724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5642\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.5568\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.5499\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.5436\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5975 - val_loss: 0.5378\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5935 - val_loss: 0.5324\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 0.5268\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5867 - val_loss: 0.5222\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 0.5178\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 0.5140\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5783 - val_loss: 0.5099\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5758 - val_loss: 0.5064\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5736 - val_loss: 0.5031\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 0.5006\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5694 - val_loss: 0.4973\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5678 - val_loss: 0.4948\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - val_loss: 0.4929\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5645 - val_loss: 0.4907\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5633 - val_loss: 0.4887\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5620 - val_loss: 0.4866\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 0.4848\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 0.4833\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5586 - val_loss: 0.4817\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5575 - val_loss: 0.4803\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.4793\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5559 - val_loss: 0.4778\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5552 - val_loss: 0.4767\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5544 - val_loss: 0.4758\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.4746\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5532 - val_loss: 0.4737\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5526 - val_loss: 0.4731\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.4721\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 0.4718\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 0.4713\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5507 - val_loss: 0.4701\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.4698\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5501 - val_loss: 0.4694\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 0.4687\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.4682\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.4683\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 0.4675\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.4674\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.4673\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.4671\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5481 - val_loss: 0.4668\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5478 - val_loss: 0.4667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5476 - val_loss: 0.4662\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5475 - val_loss: 0.4661\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 0.4657\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.4658\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 0.4656\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.4653\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 0.4652\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 0.4652\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.4655\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.4651\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.4649\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.4650\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.4647\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.4647\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.4644\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.4644\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - val_loss: 0.4648\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.4643\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.4645\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.4645\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5455 - val_loss: 0.4650\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.4642\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.4641\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5453 - val_loss: 0.4645\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.4646\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4646\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.4641\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4644\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4641\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.4642\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4642\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.4640\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.4642\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - val_loss: 0.4638\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4638\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.4638\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.4636\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5454 - val_loss: 0.4640\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5458 - val_loss: 0.4636\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.4638\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.4637\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - val_loss: 0.4639\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.4638\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.4640\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5121\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.6040 - val_loss: 2.8809\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1647 - val_loss: 1.3619\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1563 - val_loss: 0.8711\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8163 - val_loss: 0.7008\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6922 - val_loss: 0.6359\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6432 - val_loss: 0.6088\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.5938\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.5845\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.5753\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 0.5689\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5894 - val_loss: 0.5614\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5844 - val_loss: 0.5540\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5800 - val_loss: 0.5484\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5422\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5719 - val_loss: 0.5374\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 0.5326\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - val_loss: 0.5286\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - val_loss: 0.5237\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5591 - val_loss: 0.5196\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5566 - val_loss: 0.5170\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.5135\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.5100\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5498 - val_loss: 0.5069\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5479 - val_loss: 0.5048\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.5021\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.4998\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.4973\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.4948\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 0.4932\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 0.4924\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5378 - val_loss: 0.4912\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5367 - val_loss: 0.4889\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.4881\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.4872\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.4854\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.4847\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 0.4833\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.4827\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.4809\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.4810\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.4806\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.4790\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.4782\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.4785\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 0.4773\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.4772\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.4763\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.4765\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.4755\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.4749\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.4753\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.4751\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.4742\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.4748\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.4734\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.4729\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.4730\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 0.4721\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.4728\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.4725\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.4731\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.4722\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.4712\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.4710\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 0.4715\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.4716\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.4716\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.4714\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5243 - val_loss: 0.4711\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5242 - val_loss: 0.4707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.4705\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.4706\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.4709\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.4710\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.4708\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4709\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.4706\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.4712\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4703\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.4702\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5236 - val_loss: 0.4697\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5238 - val_loss: 0.4702\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4699\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.4704\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.4703\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4702\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4706\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4705\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.4694\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.4697\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.4699\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4699\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4700\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4704\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4700\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.4695\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.4687\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4701\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.4705\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5235 - val_loss: 0.4703\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5616\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmrod\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [-0.54877905 -0.40299127 -0.4191121          nan -0.46334253         nan\n",
      " -0.45120211 -0.38428165 -0.38127089 -0.54064802]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5917 - val_loss: 0.4706\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4577 - val_loss: 0.7391\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4291 - val_loss: 0.9135\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 1.9290\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4374 - val_loss: 1.6523\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 2.0498\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 2.9140\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 3.8825\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 3.9781\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 4.2102\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3689 - val_loss: 6.0783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F841D6D460>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F83D3C2D30>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,\n",
    "                                  cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37f43280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.88589984],\n",
       "        [1.3861272 ],\n",
       "        [1.9481266 ]], dtype=float32),\n",
       " array([1.569, 1.176, 2.554]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_.model.predict(X_test[:3]), y_test[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
